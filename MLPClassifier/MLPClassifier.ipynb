{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3907452c",
   "metadata": {},
   "source": [
    "# Implement classification using Multilayer perceptron\n",
    "\n",
    "In this notebook, we will implement a classification task using a **Multilayer Perceptron (MLP)** model. The steps involved include data preparation, feature and target selection, model initialization, training, and evaluation. \n",
    "\n",
    "## Step 1: Import Libraries\n",
    "\n",
    "First, we import the necessary libraries for data manipulation and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18f7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b712e",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preview Dataset\n",
    "\n",
    "We load the dataset and take a look at the first few rows to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5557fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of projects</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;50000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;50000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;50000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;50000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;50000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of projects Salary   Sales Grades\n",
       "0                   1    Low  <50000      A\n",
       "1                   2    Low  <50000      A\n",
       "2                   3    Low  <50000      A\n",
       "3                   4    Low  <50000      A\n",
       "4                   5    Low  <50000      A"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Salary.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85505f57",
   "metadata": {},
   "source": [
    "## Step 3: Encode Categorical Variables\n",
    "\n",
    "We use `LabelEncoder` to transform categorical variables into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191474db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    2\n",
      "11    2\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    2\n",
      "19    2\n",
      "20    2\n",
      "21    2\n",
      "22    2\n",
      "23    2\n",
      "24    2\n",
      "25    2\n",
      "26    2\n",
      "27    2\n",
      "28    2\n",
      "29    2\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "Name: Salary, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "data['Salary'] = le.fit_transform(data['Salary'])\n",
    "data['Sales'] = le.fit_transform(data['Sales'])\n",
    "print(data['Salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5b210",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Features and Target Variable\n",
    "\n",
    "We select the features and target variable for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206d3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['Number of projects', 'Salary', 'Sales']]\n",
    "y = data['Grades']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452467bb",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into Training and Testing Sets\n",
    "\n",
    "We split the dataset into training and testing sets to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270e16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a85355",
   "metadata": {},
   "source": [
    "## Step 6: Define and Train the Model\n",
    "\n",
    "We define the `MLPClassifier` model and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871c4e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.35024008\n",
      "Iteration 2, loss = 4.27751512\n",
      "Iteration 3, loss = 4.20527443\n",
      "Iteration 4, loss = 4.13349889\n",
      "Iteration 5, loss = 4.06223586\n",
      "Iteration 6, loss = 3.99148883\n",
      "Iteration 7, loss = 3.92127260\n",
      "Iteration 8, loss = 3.85160227\n",
      "Iteration 9, loss = 3.78249334\n",
      "Iteration 10, loss = 3.71396168\n",
      "Iteration 11, loss = 3.64602364\n",
      "Iteration 12, loss = 3.57869606\n",
      "Iteration 13, loss = 3.51199634\n",
      "Iteration 14, loss = 3.44594254\n",
      "Iteration 15, loss = 3.38055341\n",
      "Iteration 16, loss = 3.31584850\n",
      "Iteration 17, loss = 3.25184825\n",
      "Iteration 18, loss = 3.18857404\n",
      "Iteration 19, loss = 3.12604833\n",
      "Iteration 20, loss = 3.06427804\n",
      "Iteration 21, loss = 3.00318835\n",
      "Iteration 22, loss = 2.94291643\n",
      "Iteration 23, loss = 2.88349101\n",
      "Iteration 24, loss = 2.82494214\n",
      "Iteration 25, loss = 2.76730121\n",
      "Iteration 26, loss = 2.71060096\n",
      "Iteration 27, loss = 2.65487551\n",
      "Iteration 28, loss = 2.60016023\n",
      "Iteration 29, loss = 2.54649160\n",
      "Iteration 30, loss = 2.49390696\n",
      "Iteration 31, loss = 2.44244414\n",
      "Iteration 32, loss = 2.39214096\n",
      "Iteration 33, loss = 2.34303461\n",
      "Iteration 34, loss = 2.29516075\n",
      "Iteration 35, loss = 2.24855258\n",
      "Iteration 36, loss = 2.20323956\n",
      "Iteration 37, loss = 2.15924606\n",
      "Iteration 38, loss = 2.11658990\n",
      "Iteration 39, loss = 2.07528083\n",
      "Iteration 40, loss = 2.03531918\n",
      "Iteration 41, loss = 1.99669493\n",
      "Iteration 42, loss = 1.95938725\n",
      "Iteration 43, loss = 1.92336476\n",
      "Iteration 44, loss = 1.88858638\n",
      "Iteration 45, loss = 1.85500270\n",
      "Iteration 46, loss = 1.82255791\n",
      "Iteration 47, loss = 1.79119164\n",
      "Iteration 48, loss = 1.76083904\n",
      "Iteration 49, loss = 1.73143501\n",
      "Iteration 50, loss = 1.70291511\n",
      "Iteration 51, loss = 1.67521736\n",
      "Iteration 52, loss = 1.64828374\n",
      "Iteration 53, loss = 1.62197583\n",
      "Iteration 54, loss = 1.59631140\n",
      "Iteration 55, loss = 1.57126231\n",
      "Iteration 56, loss = 1.54678281\n",
      "Iteration 57, loss = 1.52280500\n",
      "Iteration 58, loss = 1.49937021\n",
      "Iteration 59, loss = 1.47647048\n",
      "Iteration 60, loss = 1.45410448\n",
      "Iteration 61, loss = 1.43227703\n",
      "Iteration 62, loss = 1.41099855\n",
      "Iteration 63, loss = 1.39028441\n",
      "Iteration 64, loss = 1.37019556\n",
      "Iteration 65, loss = 1.35074967\n",
      "Iteration 66, loss = 1.33193972\n",
      "Iteration 67, loss = 1.31379250\n",
      "Iteration 68, loss = 1.29633554\n",
      "Iteration 69, loss = 1.27959605\n",
      "Iteration 70, loss = 1.26359987\n",
      "Iteration 71, loss = 1.24837032\n",
      "Iteration 72, loss = 1.23392710\n",
      "Iteration 73, loss = 1.22028518\n",
      "Iteration 74, loss = 1.20745386\n",
      "Iteration 75, loss = 1.19543582\n",
      "Iteration 76, loss = 1.18422649\n",
      "Iteration 77, loss = 1.17381355\n",
      "Iteration 78, loss = 1.16420939\n",
      "Iteration 79, loss = 1.15538123\n",
      "Iteration 80, loss = 1.14726729\n",
      "Iteration 81, loss = 1.13982506\n",
      "Iteration 82, loss = 1.13300654\n",
      "Iteration 83, loss = 1.12675956\n",
      "Iteration 84, loss = 1.12103131\n",
      "Iteration 85, loss = 1.11580150\n",
      "Iteration 86, loss = 1.11097685\n",
      "Iteration 87, loss = 1.10650291\n",
      "Iteration 88, loss = 1.10232837\n",
      "Iteration 89, loss = 1.09840606\n",
      "Iteration 90, loss = 1.09469379\n",
      "Iteration 91, loss = 1.09115483\n",
      "Iteration 92, loss = 1.08775812\n",
      "Iteration 93, loss = 1.08447830\n",
      "Iteration 94, loss = 1.08129533\n",
      "Iteration 95, loss = 1.07819410\n",
      "Iteration 96, loss = 1.07516378\n",
      "Iteration 97, loss = 1.07219715\n",
      "Iteration 98, loss = 1.06928111\n",
      "Iteration 99, loss = 1.06630198\n",
      "Iteration 100, loss = 1.06336602\n",
      "Iteration 101, loss = 1.06047551\n",
      "Iteration 102, loss = 1.05763267\n",
      "Iteration 103, loss = 1.05483934\n",
      "Iteration 104, loss = 1.05209672\n",
      "Iteration 105, loss = 1.04940518\n",
      "Iteration 106, loss = 1.04676419\n",
      "Iteration 107, loss = 1.04418957\n",
      "Iteration 108, loss = 1.04168769\n",
      "Iteration 109, loss = 1.03923260\n",
      "Iteration 110, loss = 1.03682046\n",
      "Iteration 111, loss = 1.03444716\n",
      "Iteration 112, loss = 1.03210847\n",
      "Iteration 113, loss = 1.02980022\n",
      "Iteration 114, loss = 1.02751843\n",
      "Iteration 115, loss = 1.02525945\n",
      "Iteration 116, loss = 1.02304020\n",
      "Iteration 117, loss = 1.02083971\n",
      "Iteration 118, loss = 1.01872068\n",
      "Iteration 119, loss = 1.01662855\n",
      "Iteration 120, loss = 1.01455128\n",
      "Iteration 121, loss = 1.01248734\n",
      "Iteration 122, loss = 1.01043565\n",
      "Iteration 123, loss = 1.00839552\n",
      "Iteration 124, loss = 1.00636661\n",
      "Iteration 125, loss = 1.00434881\n",
      "Iteration 126, loss = 1.00234220\n",
      "Iteration 127, loss = 1.00034699\n",
      "Iteration 128, loss = 0.99836347\n",
      "Iteration 129, loss = 0.99639193\n",
      "Iteration 130, loss = 0.99443266\n",
      "Iteration 131, loss = 0.99248590\n",
      "Iteration 132, loss = 0.99055182\n",
      "Iteration 133, loss = 0.98863054\n",
      "Iteration 134, loss = 0.98672208\n",
      "Iteration 135, loss = 0.98482637\n",
      "Iteration 136, loss = 0.98294330\n",
      "Iteration 137, loss = 0.98110883\n",
      "Iteration 138, loss = 0.97931739\n",
      "Iteration 139, loss = 0.97758259\n",
      "Iteration 140, loss = 0.97588943\n",
      "Iteration 141, loss = 0.97421882\n",
      "Iteration 142, loss = 0.97256387\n",
      "Iteration 143, loss = 0.97092355\n",
      "Iteration 144, loss = 0.96929689\n",
      "Iteration 145, loss = 0.96768305\n",
      "Iteration 146, loss = 0.96608126\n",
      "Iteration 147, loss = 0.96449083\n",
      "Iteration 148, loss = 0.96291117\n",
      "Iteration 149, loss = 0.96134175\n",
      "Iteration 150, loss = 0.95978210\n",
      "Iteration 151, loss = 0.95823183\n",
      "Iteration 152, loss = 0.95669059\n",
      "Iteration 153, loss = 0.95515807\n",
      "Iteration 154, loss = 0.95363402\n",
      "Iteration 155, loss = 0.95211818\n",
      "Iteration 156, loss = 0.95061036\n",
      "Iteration 157, loss = 0.94911038\n",
      "Iteration 158, loss = 0.94761805\n",
      "Iteration 159, loss = 0.94613323\n",
      "Iteration 160, loss = 0.94465578\n",
      "Iteration 161, loss = 0.94318554\n",
      "Iteration 162, loss = 0.94172241\n",
      "Iteration 163, loss = 0.94026624\n",
      "Iteration 164, loss = 0.93881693\n",
      "Iteration 165, loss = 0.93737436\n",
      "Iteration 166, loss = 0.93593842\n",
      "Iteration 167, loss = 0.93450902\n",
      "Iteration 168, loss = 0.93308604\n",
      "Iteration 169, loss = 0.93166940\n",
      "Iteration 170, loss = 0.93025902\n",
      "Iteration 171, loss = 0.92885480\n",
      "Iteration 172, loss = 0.92745667\n",
      "Iteration 173, loss = 0.92606456\n",
      "Iteration 174, loss = 0.92467840\n",
      "Iteration 175, loss = 0.92325875\n",
      "Iteration 176, loss = 0.92178872\n",
      "Iteration 177, loss = 0.92030622\n",
      "Iteration 178, loss = 0.91883012\n",
      "Iteration 179, loss = 0.91735712\n",
      "Iteration 180, loss = 0.91587982\n",
      "Iteration 181, loss = 0.91439980\n",
      "Iteration 182, loss = 0.91291844\n",
      "Iteration 183, loss = 0.91143696\n",
      "Iteration 184, loss = 0.90995644\n",
      "Iteration 185, loss = 0.90847782\n",
      "Iteration 186, loss = 0.90700190\n",
      "Iteration 187, loss = 0.90552941\n",
      "Iteration 188, loss = 0.90413003\n",
      "Iteration 189, loss = 0.90275350\n",
      "Iteration 190, loss = 0.90138657\n",
      "Iteration 191, loss = 0.90002881\n",
      "Iteration 192, loss = 0.89867983\n",
      "Iteration 193, loss = 0.89733926\n",
      "Iteration 194, loss = 0.89600678\n",
      "Iteration 195, loss = 0.89468208\n",
      "Iteration 196, loss = 0.89336486\n",
      "Iteration 197, loss = 0.89205486\n",
      "Iteration 198, loss = 0.89075183\n",
      "Iteration 199, loss = 0.88945553\n",
      "Iteration 200, loss = 0.88816574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataD\\Apps\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(6, 5),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.001)\n",
    "\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6e6db",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions and Evaluate the Model\n",
    "\n",
    "We make predictions on the test set and evaluate the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcdab1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, ypred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f8eab",
   "metadata": {},
   "source": [
    "## Step 8: Load and Preview Another Dataset\n",
    "\n",
    "We load a different dataset to demonstrate the process on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf3fb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a3500d",
   "metadata": {},
   "source": [
    "## Step 9: Encode Categorical Variables for New Dataset\n",
    "\n",
    "We apply `LabelEncoder` to the categorical variables in the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c303d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    1\n",
      "9996    1\n",
      "9997    0\n",
      "9998    1\n",
      "9999    0\n",
      "Name: Gender, Length: 10000, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "data['Geography'] = le.fit_transform(data['Geography'])\n",
    "data['Surname'] = le.fit_transform(data['Surname'])\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "print(data['Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f43962",
   "metadata": {},
   "source": [
    "## Step 10: Prepare Features and Target Variable for New Dataset\n",
    "\n",
    "We select the features and target variable for the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290a22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80ecc3",
   "metadata": {},
   "source": [
    "## Step 11: Split Data into Training and Testing Sets for New Dataset\n",
    "\n",
    "We split the new dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6dfe188",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992cd65",
   "metadata": {},
   "source": [
    "## Step 12: Define and Train the Model on New Dataset\n",
    "\n",
    "We define the `MLPClassifier` model and fit it to the new training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f946f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 28.56202488\n",
      "Iteration 2, loss = 28.56202461\n",
      "Iteration 3, loss = 28.56202437\n",
      "Iteration 4, loss = 18.86385498\n",
      "Iteration 5, loss = 0.59713872\n",
      "Iteration 6, loss = 0.59505177\n",
      "Iteration 7, loss = 0.59297825\n",
      "Iteration 8, loss = 0.59079085\n",
      "Iteration 9, loss = 0.58851819\n",
      "Iteration 10, loss = 0.58618606\n",
      "Iteration 11, loss = 0.58380664\n",
      "Iteration 12, loss = 0.58140531\n",
      "Iteration 13, loss = 0.57897278\n",
      "Iteration 14, loss = 0.57653017\n",
      "Iteration 15, loss = 0.57412865\n",
      "Iteration 16, loss = 0.57168662\n",
      "Iteration 17, loss = 0.56930693\n",
      "Iteration 18, loss = 0.56694095\n",
      "Iteration 19, loss = 0.56461189\n",
      "Iteration 20, loss = 0.56231332\n",
      "Iteration 21, loss = 0.56005580\n",
      "Iteration 22, loss = 0.55788343\n",
      "Iteration 23, loss = 0.55571434\n",
      "Iteration 24, loss = 0.55362443\n",
      "Iteration 25, loss = 0.55158709\n",
      "Iteration 26, loss = 0.54960439\n",
      "Iteration 27, loss = 0.54769170\n",
      "Iteration 28, loss = 0.54582433\n",
      "Iteration 29, loss = 0.54403202\n",
      "Iteration 30, loss = 0.54231290\n",
      "Iteration 31, loss = 0.54061668\n",
      "Iteration 32, loss = 0.53901652\n",
      "Iteration 33, loss = 0.53745644\n",
      "Iteration 34, loss = 0.53597212\n",
      "Iteration 35, loss = 0.53455255\n",
      "Iteration 36, loss = 0.53318887\n",
      "Iteration 37, loss = 0.53185458\n",
      "Iteration 38, loss = 0.53061152\n",
      "Iteration 39, loss = 0.52942326\n",
      "Iteration 40, loss = 0.52826679\n",
      "Iteration 41, loss = 0.52719057\n",
      "Iteration 42, loss = 0.52615036\n",
      "Iteration 43, loss = 0.52516783\n",
      "Iteration 44, loss = 0.52422228\n",
      "Iteration 45, loss = 0.52335117\n",
      "Iteration 46, loss = 0.52249565\n",
      "Iteration 47, loss = 0.52169303\n",
      "Iteration 48, loss = 0.52095532\n",
      "Iteration 49, loss = 0.52023588\n",
      "Iteration 50, loss = 0.51957392\n",
      "Iteration 51, loss = 0.51892855\n",
      "Iteration 52, loss = 0.51833059\n",
      "Iteration 53, loss = 0.51777715\n",
      "Iteration 54, loss = 0.51724803\n",
      "Iteration 55, loss = 0.51675618\n",
      "Iteration 56, loss = 0.51628707\n",
      "Iteration 57, loss = 0.51586193\n",
      "Iteration 58, loss = 0.51544141\n",
      "Iteration 59, loss = 0.51508335\n",
      "Iteration 60, loss = 0.51471061\n",
      "Iteration 61, loss = 0.51438974\n",
      "Iteration 62, loss = 0.51408772\n",
      "Iteration 63, loss = 0.51379259\n",
      "Iteration 64, loss = 0.51353271\n",
      "Iteration 65, loss = 0.51328310\n",
      "Iteration 66, loss = 0.51306023\n",
      "Iteration 67, loss = 0.51284484\n",
      "Iteration 68, loss = 0.51265880\n",
      "Iteration 69, loss = 0.51247459\n",
      "Iteration 70, loss = 0.51230859\n",
      "Iteration 71, loss = 0.51215983\n",
      "Iteration 72, loss = 0.51202004\n",
      "Iteration 73, loss = 0.51189099\n",
      "Iteration 74, loss = 0.51178060\n",
      "Iteration 75, loss = 0.51166856\n",
      "Iteration 76, loss = 0.51157359\n",
      "Iteration 77, loss = 0.51148664\n",
      "Iteration 78, loss = 0.51140327\n",
      "Iteration 79, loss = 0.51133247\n",
      "Iteration 80, loss = 0.51126601\n",
      "Iteration 81, loss = 0.51120529\n",
      "Iteration 82, loss = 0.51115446\n",
      "Iteration 83, loss = 0.51110084\n",
      "Iteration 84, loss = 0.51105975\n",
      "Iteration 85, loss = 0.51101986\n",
      "Iteration 86, loss = 0.51098417\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(6, 5),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.001)\n",
    "\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c3c77",
   "metadata": {},
   "source": [
    "## Step 13: Make Predictions and Evaluate the Model on New Dataset\n",
    "\n",
    "We make predictions on the new test set and evaluate the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd58f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8053333333333333\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, ypred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bb13b",
   "metadata": {},
   "source": [
    "## Step 14: Load and Preview Another Dataset\n",
    "\n",
    "We load a third dataset to demonstrate the process with different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1719ef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Iris.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198a3f6",
   "metadata": {},
   "source": [
    "## Step 15: Encode Categorical Variables for Third Dataset\n",
    "\n",
    "We apply `LabelEncoder` to the categorical variables in the third dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b08e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: Species, Length: 150, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "data['Species'] = le.fit_transform(data['Species'])\n",
    "print(data['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71a261",
   "metadata": {},
   "source": [
    "## Step 16: Prepare Features and Target Variable for Third Dataset\n",
    "\n",
    "We select the features and target variable for the third dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cea020ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = data['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150e28e",
   "metadata": {},
   "source": [
    "## Step 17: Split Data into Training and Testing Sets for Third Dataset\n",
    "\n",
    "We split the third dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "538da37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dae23",
   "metadata": {},
   "source": [
    "## Step 18: Define and Train the Model on Third Dataset\n",
    "\n",
    "We define the `MLPClassifier` model and fit it to the third training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1de63dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.36131233\n",
      "Iteration 2, loss = 2.24877832\n",
      "Iteration 3, loss = 2.13732710\n",
      "Iteration 4, loss = 2.03001088\n",
      "Iteration 5, loss = 1.92668727\n",
      "Iteration 6, loss = 1.83047885\n",
      "Iteration 7, loss = 1.74660175\n",
      "Iteration 8, loss = 1.67553905\n",
      "Iteration 9, loss = 1.62057211\n",
      "Iteration 10, loss = 1.58495280\n",
      "Iteration 11, loss = 1.57260507\n",
      "Iteration 12, loss = 1.58241877\n",
      "Iteration 13, loss = 1.60179372\n",
      "Iteration 14, loss = 1.61879317\n",
      "Iteration 15, loss = 1.62674265\n",
      "Iteration 16, loss = 1.62375979\n",
      "Iteration 17, loss = 1.61083158\n",
      "Iteration 18, loss = 1.59040152\n",
      "Iteration 19, loss = 1.56554110\n",
      "Iteration 20, loss = 1.53947289\n",
      "Iteration 21, loss = 1.51519008\n",
      "Iteration 22, loss = 1.49503201\n",
      "Iteration 23, loss = 1.48022592\n",
      "Iteration 24, loss = 1.47058580\n",
      "Iteration 25, loss = 1.46433654\n",
      "Iteration 26, loss = 1.45975115\n",
      "Iteration 27, loss = 1.45505525\n",
      "Iteration 28, loss = 1.44870559\n",
      "Iteration 29, loss = 1.43991563\n",
      "Iteration 30, loss = 1.42861219\n",
      "Iteration 31, loss = 1.41470148\n",
      "Iteration 32, loss = 1.39957141\n",
      "Iteration 33, loss = 1.38434750\n",
      "Iteration 34, loss = 1.36996675\n",
      "Iteration 35, loss = 1.35699704\n",
      "Iteration 36, loss = 1.34558137\n",
      "Iteration 37, loss = 1.33545746\n",
      "Iteration 38, loss = 1.32612340\n",
      "Iteration 39, loss = 1.31697819\n",
      "Iteration 40, loss = 1.30748798\n",
      "Iteration 41, loss = 1.29736497\n",
      "Iteration 42, loss = 1.28649577\n",
      "Iteration 43, loss = 1.27496787\n",
      "Iteration 44, loss = 1.26301473\n",
      "Iteration 45, loss = 1.25093935\n",
      "Iteration 46, loss = 1.23903466\n",
      "Iteration 47, loss = 1.22751681\n",
      "Iteration 48, loss = 1.21647458\n",
      "Iteration 49, loss = 1.20588250\n",
      "Iteration 50, loss = 1.19562949\n",
      "Iteration 51, loss = 1.18555067\n",
      "Iteration 52, loss = 1.17548448\n",
      "Iteration 53, loss = 1.16530563\n",
      "Iteration 54, loss = 1.15496549\n",
      "Iteration 55, loss = 1.14450061\n",
      "Iteration 56, loss = 1.13400299\n",
      "Iteration 57, loss = 1.12358712\n",
      "Iteration 58, loss = 1.11328487\n",
      "Iteration 59, loss = 1.10319626\n",
      "Iteration 60, loss = 1.09337921\n",
      "Iteration 61, loss = 1.08381900\n",
      "Iteration 62, loss = 1.07447517\n",
      "Iteration 63, loss = 1.06530132\n",
      "Iteration 64, loss = 1.05626317\n",
      "Iteration 65, loss = 1.04735038\n",
      "Iteration 66, loss = 1.03858005\n",
      "Iteration 67, loss = 1.02999250\n",
      "Iteration 68, loss = 1.02164160\n",
      "Iteration 69, loss = 1.01358339\n",
      "Iteration 70, loss = 1.00586611\n",
      "Iteration 71, loss = 0.99852434\n",
      "Iteration 72, loss = 0.99157823\n",
      "Iteration 73, loss = 0.98503717\n",
      "Iteration 74, loss = 0.97890596\n",
      "Iteration 75, loss = 0.97319114\n",
      "Iteration 76, loss = 0.96790504\n",
      "Iteration 77, loss = 0.96307449\n",
      "Iteration 78, loss = 0.95871634\n",
      "Iteration 79, loss = 0.95484854\n",
      "Iteration 80, loss = 0.95148400\n",
      "Iteration 81, loss = 0.94862265\n",
      "Iteration 82, loss = 0.94624838\n",
      "Iteration 83, loss = 0.94432866\n",
      "Iteration 84, loss = 0.94281647\n",
      "Iteration 85, loss = 0.94165397\n",
      "Iteration 86, loss = 0.94077685\n",
      "Iteration 87, loss = 0.94011851\n",
      "Iteration 88, loss = 0.93961361\n",
      "Iteration 89, loss = 0.93919115\n",
      "Iteration 90, loss = 0.93879018\n",
      "Iteration 91, loss = 0.93837490\n",
      "Iteration 92, loss = 0.93788580\n",
      "Iteration 93, loss = 0.93731389\n",
      "Iteration 94, loss = 0.93663549\n",
      "Iteration 95, loss = 0.93583731\n",
      "Iteration 96, loss = 0.93491930\n",
      "Iteration 97, loss = 0.93389112\n",
      "Iteration 98, loss = 0.93277044\n",
      "Iteration 99, loss = 0.93158047\n",
      "Iteration 100, loss = 0.93034699\n",
      "Iteration 101, loss = 0.92909541\n",
      "Iteration 102, loss = 0.92784829\n",
      "Iteration 103, loss = 0.92662360\n",
      "Iteration 104, loss = 0.92543405\n",
      "Iteration 105, loss = 0.92428718\n",
      "Iteration 106, loss = 0.92318621\n",
      "Iteration 107, loss = 0.92213107\n",
      "Iteration 108, loss = 0.92111958\n",
      "Iteration 109, loss = 0.92014824\n",
      "Iteration 110, loss = 0.91921282\n",
      "Iteration 111, loss = 0.91821972\n",
      "Iteration 112, loss = 0.91711934\n",
      "Iteration 113, loss = 0.91601026\n",
      "Iteration 114, loss = 0.91489395\n",
      "Iteration 115, loss = 0.91377340\n",
      "Iteration 116, loss = 0.91264822\n",
      "Iteration 117, loss = 0.91150759\n",
      "Iteration 118, loss = 0.91031075\n",
      "Iteration 119, loss = 0.90910016\n",
      "Iteration 120, loss = 0.90788257\n",
      "Iteration 121, loss = 0.90666072\n",
      "Iteration 122, loss = 0.90544188\n",
      "Iteration 123, loss = 0.90398537\n",
      "Iteration 124, loss = 0.90247234\n",
      "Iteration 125, loss = 0.90095005\n",
      "Iteration 126, loss = 0.89942715\n",
      "Iteration 127, loss = 0.89791086\n",
      "Iteration 128, loss = 0.89640712\n",
      "Iteration 129, loss = 0.89492084\n",
      "Iteration 130, loss = 0.89345597\n",
      "Iteration 131, loss = 0.89201111\n",
      "Iteration 132, loss = 0.89058926\n",
      "Iteration 133, loss = 0.88920226\n",
      "Iteration 134, loss = 0.88784040\n",
      "Iteration 135, loss = 0.88643934\n",
      "Iteration 136, loss = 0.88506142\n",
      "Iteration 137, loss = 0.88370703\n",
      "Iteration 138, loss = 0.88237616\n",
      "Iteration 139, loss = 0.88106861\n",
      "Iteration 140, loss = 0.87978397\n",
      "Iteration 141, loss = 0.87852172\n",
      "Iteration 142, loss = 0.87728126\n",
      "Iteration 143, loss = 0.87606189\n",
      "Iteration 144, loss = 0.87486291\n",
      "Iteration 145, loss = 0.87368360\n",
      "Iteration 146, loss = 0.87252327\n",
      "Iteration 147, loss = 0.87138130\n",
      "Iteration 148, loss = 0.87025709\n",
      "Iteration 149, loss = 0.86915014\n",
      "Iteration 150, loss = 0.86805995\n",
      "Iteration 151, loss = 0.86698607\n",
      "Iteration 152, loss = 0.86591652\n",
      "Iteration 153, loss = 0.86479634\n",
      "Iteration 154, loss = 0.86368582\n",
      "Iteration 155, loss = 0.86258531\n",
      "Iteration 156, loss = 0.86141786\n",
      "Iteration 157, loss = 0.85991073\n",
      "Iteration 158, loss = 0.85838219\n",
      "Iteration 159, loss = 0.85684309\n",
      "Iteration 160, loss = 0.85530228\n",
      "Iteration 161, loss = 0.85371016\n",
      "Iteration 162, loss = 0.85205535\n",
      "Iteration 163, loss = 0.85041710\n",
      "Iteration 164, loss = 0.84879975\n",
      "Iteration 165, loss = 0.84719657\n",
      "Iteration 166, loss = 0.84561059\n",
      "Iteration 167, loss = 0.84403904\n",
      "Iteration 168, loss = 0.84232818\n",
      "Iteration 169, loss = 0.84062825\n",
      "Iteration 170, loss = 0.83894230\n",
      "Iteration 171, loss = 0.83727264\n",
      "Iteration 172, loss = 0.83549570\n",
      "Iteration 173, loss = 0.83367349\n",
      "Iteration 174, loss = 0.83185864\n",
      "Iteration 175, loss = 0.82995541\n",
      "Iteration 176, loss = 0.82796726\n",
      "Iteration 177, loss = 0.82598023\n",
      "Iteration 178, loss = 0.82383385\n",
      "Iteration 179, loss = 0.82166150\n",
      "Iteration 180, loss = 0.81948676\n",
      "Iteration 181, loss = 0.81728653\n",
      "Iteration 182, loss = 0.81489027\n",
      "Iteration 183, loss = 0.81248843\n",
      "Iteration 184, loss = 0.81012020\n",
      "Iteration 185, loss = 0.80752750\n",
      "Iteration 186, loss = 0.80494666\n",
      "Iteration 187, loss = 0.80253100\n",
      "Iteration 188, loss = 0.80017625\n",
      "Iteration 189, loss = 0.79788705\n",
      "Iteration 190, loss = 0.79577835\n",
      "Iteration 191, loss = 0.79377547\n",
      "Iteration 192, loss = 0.79178123\n",
      "Iteration 193, loss = 0.78987701\n",
      "Iteration 194, loss = 0.78794348\n",
      "Iteration 195, loss = 0.78560425\n",
      "Iteration 196, loss = 0.78333369\n",
      "Iteration 197, loss = 0.78085215\n",
      "Iteration 198, loss = 0.77840235\n",
      "Iteration 199, loss = 0.77597507\n",
      "Iteration 200, loss = 0.77314378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataD\\Apps\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(6, 5),\n",
    "                    random_state=5,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.001)\n",
    "\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0301ff",
   "metadata": {},
   "source": [
    "## Step 19: Make Predictions and Evaluate the Model on Third Dataset\n",
    "\n",
    "We make predictions on the third test set and evaluate the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a385833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 1 2 0 1 2 2 2 2 0 2 0 0 1 2 2 1 2 1 2 0 2 2 2 2 2 1 2 0 0 2 0 1 2 1\n",
      " 0 0 2 2 1 2 0 0]\n",
      "Accuracy: 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "ypred = clf.predict(x_test)\n",
    "print(ypred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, ypred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
